{
    "accuracy": {
        "runs":
        [
            "Best Parameters: {"learning_rate": 0.1, "max_depth": 7, "min_child_weight": 1, "n_estimators": 150, "reg_alpha": 0.1, "subsample": 0.8}" 0.76,
            "Best Parameters: {"learning_rate": 0.05, "max_depth": 7, "min_child_weight": 1, "n_estimators": 150, "reg_alpha": 0.01, "subsample": 0.8}" 0.64
            "Best Parameters: {"learning_rate": 0.1, "max_depth": 9, "min_child_weight": 1, "n_estimators": 200, "reg_alpha": 0.1, "subsample": 1}" 0.76
        ]
    },
    "balance_accuracy":{
        "runs":
        [
        Best Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'subsample': 0.8} 0.76,

        Best Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'subsample': 0.8}0.79 ()    
            xbm.set_params(
            n_estimators=200,  # Increase boosting rounds
            min_child_weight=0.5,  # Allow more granular splits
            scale_pos_weight=[scale_pos_weight[i] for i in sorted(scale_pos_weight.keys())]  # Class balancing
            )

        ]
    }
}